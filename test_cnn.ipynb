{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Classification For Hand Poses\n",
    "This script shows how to build a convolutional neural network to classify different hand poses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random, shutil\n",
    "import imageio.v3 as imageio\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down  fist  left  right  up\n",
      "The number of classes: 5\n"
     ]
    }
   ],
   "source": [
    "!ls data/train\n",
    "\n",
    "# define the number of output K\n",
    "num_classes = len(os.listdir('data/train'))\n",
    "print(f\"The number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder environments for training and testing\n",
    "os.makedirs(name=\"data\", exist_ok=True)\n",
    "\n",
    "os.makedirs(name=\"data/train\", exist_ok=True)\n",
    "os.makedirs(name=\"data/test\", exist_ok=True)\n",
    "\n",
    "os.makedirs(name=\"data/train/fist\", exist_ok=True)      # label 0 for training\n",
    "os.makedirs(name=\"data/train/up\", exist_ok=True)        # label 1 for training\n",
    "os.makedirs(name=\"data/train/left\", exist_ok=True)      # label 2 for training\n",
    "os.makedirs(name=\"data/train/down\", exist_ok=True)      # label 3 for training\n",
    "os.makedirs(name=\"data/train/right\", exist_ok=True)     # label 4 for training\n",
    "\n",
    "os.makedirs(name=\"data/test/fist\", exist_ok=True)       # label 0 for testing\n",
    "os.makedirs(name=\"data/test/up\", exist_ok=True)         # label 1 for testing\n",
    "os.makedirs(name=\"data/test/left\", exist_ok=True)       # label 2 for testing\n",
    "os.makedirs(name=\"data/test/down\", exist_ok=True)       # label 3 for testing\n",
    "os.makedirs(name=\"data/test/right\", exist_ok=True)      # label 4 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # randomly move image files from train to test folder\n",
    "# def random_file_move(label_name: str, ratio=0.2):\n",
    "#     # label_name: fist, up, left, down, right\n",
    "#     src = f\"data/train/{label_name}/\"\n",
    "#     dst = f\"data/test/{label_name}/\"\n",
    "    \n",
    "#     # check whether the ratio between train and test image files\n",
    "#     files_src = os.listdir(src)\n",
    "#     files_dst = os.listdir(dst)\n",
    "#     n_files_to_move = round((len(files_src) + len(files_dst)) * ratio)\n",
    "#     if n_files_to_move <= len(files_dst):\n",
    "#         # if the number of dst files is greater than or equal to the ratio of the number of total files\n",
    "#         # consider the files are already moved from train to test folder\n",
    "#         return\n",
    "#     # else move the files to meet the ratio\n",
    "#     n_files_to_move -= len(files_dst)\n",
    "#     for file_name in random.sample(files_src, n_files_to_move):\n",
    "#         shutil.move(os.path.join(src, file_name), dst)\n",
    "\n",
    "# random_file_move(\"fist\")\n",
    "# random_file_move(\"up\")\n",
    "# random_file_move(\"left\")\n",
    "# random_file_move(\"down\")\n",
    "# random_file_move(\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data transformer for train and test set\n",
    "# we can also introduce data augmentation for training if needed\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                        std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                        std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root='data/train',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root='data/test',\n",
    "    transform=test_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader to automatically generate batches in the training loop with shuffling\n",
    "batch_size = 3\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1451,  0.1608,  0.1216,  ..., -0.1294, -0.1294, -0.1059],\n",
      "          [ 0.1373,  0.1451,  0.1059,  ..., -0.1137, -0.1216, -0.1059],\n",
      "          [ 0.1294,  0.1294,  0.1137,  ..., -0.1059, -0.1137, -0.1059],\n",
      "          ...,\n",
      "          [-0.0353, -0.0353, -0.0353,  ..., -0.1686, -0.1686, -0.1608],\n",
      "          [-0.0353, -0.0353, -0.0667,  ..., -0.1451, -0.1529, -0.1451],\n",
      "          [-0.0196, -0.0196, -0.0667,  ..., -0.1373, -0.1608, -0.1529]],\n",
      "\n",
      "         [[-0.0196, -0.0039,  0.0275,  ..., -0.1373, -0.1373, -0.1137],\n",
      "          [ 0.0039,  0.0118,  0.0353,  ..., -0.1451, -0.1294, -0.1137],\n",
      "          [ 0.0353,  0.0353,  0.0431,  ..., -0.1373, -0.1373, -0.1294],\n",
      "          ...,\n",
      "          [-0.0902, -0.0902, -0.0902,  ..., -0.2000, -0.2235, -0.2157],\n",
      "          [-0.0902, -0.0902, -0.0824,  ..., -0.2000, -0.2078, -0.2000],\n",
      "          [-0.0902, -0.0902, -0.0824,  ..., -0.1922, -0.2078, -0.2000]],\n",
      "\n",
      "         [[-0.1529, -0.1373, -0.0980,  ..., -0.2549, -0.2549, -0.2314],\n",
      "          [-0.1373, -0.1294, -0.1137,  ..., -0.2314, -0.2471, -0.2314],\n",
      "          [-0.0902, -0.0902, -0.0902,  ..., -0.2235, -0.2471, -0.2392],\n",
      "          ...,\n",
      "          [-0.2392, -0.2392, -0.2392,  ..., -0.2863, -0.3020, -0.2941],\n",
      "          [-0.2549, -0.2549, -0.2627,  ..., -0.2784, -0.2863, -0.2784],\n",
      "          [-0.2549, -0.2549, -0.2627,  ..., -0.2706, -0.3098, -0.3020]]],\n",
      "\n",
      "\n",
      "        [[[-0.2627, -0.2863, -0.2941,  ..., -0.1529, -0.0745, -0.0824],\n",
      "          [-0.2314, -0.2392, -0.2000,  ..., -0.1451, -0.0980, -0.1216],\n",
      "          [-0.2078, -0.2000, -0.1451,  ..., -0.1529, -0.1529, -0.1529],\n",
      "          ...,\n",
      "          [ 0.0667,  0.0667,  0.0118,  ..., -0.4902, -0.5922, -0.6000],\n",
      "          [ 0.0667,  0.0902,  0.0431,  ..., -0.4980, -0.6235, -0.6235],\n",
      "          [ 0.0745,  0.0980,  0.0431,  ..., -0.5137, -0.5922, -0.6392]],\n",
      "\n",
      "         [[-0.1059, -0.1294, -0.1373,  ..., -0.1843, -0.2235, -0.2314],\n",
      "          [-0.1137, -0.1216, -0.1137,  ..., -0.1137, -0.2000, -0.2235],\n",
      "          [-0.1608, -0.1529, -0.1294,  ..., -0.1137, -0.1843, -0.1843],\n",
      "          ...,\n",
      "          [ 0.0588,  0.0588,  0.0510,  ..., -0.5373, -0.5529, -0.5608],\n",
      "          [ 0.0431,  0.0667,  0.0667,  ..., -0.5216, -0.5529, -0.5529],\n",
      "          [ 0.0039,  0.0275,  0.0588,  ..., -0.5294, -0.4824, -0.5294]],\n",
      "\n",
      "         [[-0.3647, -0.3882, -0.2863,  ..., -0.1765, -0.3255, -0.3333],\n",
      "          [-0.3412, -0.3490, -0.2784,  ..., -0.1686, -0.2863, -0.3098],\n",
      "          [-0.3098, -0.3020, -0.2706,  ..., -0.1922, -0.2549, -0.2549],\n",
      "          ...,\n",
      "          [-0.0588, -0.0588, -0.0275,  ..., -0.6549, -0.6627, -0.6706],\n",
      "          [-0.0824, -0.0588, -0.0588,  ..., -0.6314, -0.6941, -0.6941],\n",
      "          [-0.0667, -0.0431, -0.0667,  ..., -0.6078, -0.6392, -0.6863]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0118, -0.0039,  0.0510,  ..., -0.8431, -0.8510, -0.8275],\n",
      "          [-0.0039, -0.0039,  0.0353,  ..., -0.8431, -0.8510, -0.8353],\n",
      "          [ 0.0275,  0.0275,  0.0431,  ..., -0.8118, -0.8118, -0.7882],\n",
      "          ...,\n",
      "          [-0.0196, -0.0196, -0.0118,  ..., -0.1451, -0.1216, -0.1451],\n",
      "          [-0.0275, -0.0353, -0.0118,  ..., -0.1294, -0.1216, -0.1529],\n",
      "          [ 0.0118,  0.0039,  0.0275,  ..., -0.1294, -0.1216, -0.1608]],\n",
      "\n",
      "         [[ 0.1843,  0.1686,  0.1765,  ..., -0.8667, -0.8667, -0.8431],\n",
      "          [ 0.1922,  0.1922,  0.2078,  ..., -0.8510, -0.8353, -0.8196],\n",
      "          [ 0.2000,  0.2000,  0.2157,  ..., -0.7725, -0.7647, -0.7412],\n",
      "          ...,\n",
      "          [ 0.0902,  0.0902,  0.1059,  ..., -0.0667, -0.0431, -0.0667],\n",
      "          [ 0.1059,  0.0980,  0.1059,  ..., -0.0667, -0.0588, -0.0902],\n",
      "          [ 0.1373,  0.1294,  0.1216,  ..., -0.0510, -0.0588, -0.0980]],\n",
      "\n",
      "         [[ 0.0431,  0.0275, -0.0039,  ..., -0.9765, -0.9608, -0.9373],\n",
      "          [ 0.0275,  0.0275, -0.0039,  ..., -0.9686, -0.9608, -0.9451],\n",
      "          [ 0.0431,  0.0431, -0.0118,  ..., -0.8667, -0.8980, -0.8745],\n",
      "          ...,\n",
      "          [-0.0824, -0.0824, -0.0902,  ..., -0.1608, -0.1529, -0.1765],\n",
      "          [-0.1137, -0.1216, -0.0902,  ..., -0.1529, -0.1608, -0.1922],\n",
      "          [-0.1137, -0.1216, -0.0980,  ..., -0.1608, -0.1608, -0.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1529, -0.1608, -0.0118,  ..., -0.0118,  0.0039, -0.0196],\n",
      "          [-0.1294, -0.1294, -0.0196,  ..., -0.0353, -0.0275, -0.0431],\n",
      "          [-0.0902, -0.0824, -0.0510,  ..., -0.0588, -0.0039, -0.0275],\n",
      "          ...,\n",
      "          [ 0.2314,  0.2471,  0.1765,  ..., -0.3569, -0.4275, -0.4196],\n",
      "          [ 0.2000,  0.2157,  0.2000,  ..., -0.3882, -0.4667, -0.4510],\n",
      "          [ 0.2235,  0.2471,  0.2235,  ..., -0.3882, -0.4510, -0.4510]],\n",
      "\n",
      "         [[-0.0353, -0.0431, -0.0745,  ..., -0.0275, -0.0510, -0.0745],\n",
      "          [-0.0510, -0.0510, -0.0667,  ..., -0.0275, -0.0431, -0.0588],\n",
      "          [-0.0431, -0.0353, -0.0588,  ...,  0.0039, -0.0196, -0.0431],\n",
      "          ...,\n",
      "          [ 0.2000,  0.2157,  0.2078,  ..., -0.4353, -0.4667, -0.4588],\n",
      "          [ 0.1843,  0.2000,  0.2078,  ..., -0.4588, -0.4902, -0.4745],\n",
      "          [ 0.1529,  0.1765,  0.1922,  ..., -0.4353, -0.4588, -0.4588]],\n",
      "\n",
      "         [[-0.1608, -0.1686, -0.1686,  ..., -0.1059, -0.2157, -0.2392],\n",
      "          [-0.1765, -0.1765, -0.1686,  ..., -0.0745, -0.1373, -0.1529],\n",
      "          [-0.1765, -0.1686, -0.1765,  ..., -0.0824, -0.0824, -0.1059],\n",
      "          ...,\n",
      "          [-0.0118,  0.0039, -0.0275,  ..., -0.6549, -0.6235, -0.6157],\n",
      "          [ 0.0039,  0.0196, -0.0196,  ..., -0.6235, -0.6157, -0.6000],\n",
      "          [-0.0118,  0.0118, -0.0196,  ..., -0.5529, -0.5765, -0.5765]]]])\n",
      "torch.Size([4, 3, 360, 640])\n",
      "tensor([4, 0, 1, 0])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# understand DataLoader better\n",
    "tmp_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "for x, y in tmp_loader:\n",
    "    print(x)\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        # K is the number of output classes\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # define pooling layer\n",
    "        # max pool with (2X2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # define convolution layers\n",
    "        # convolutional layer 1 -> input: (3, 360, 640), output: (16, 180, 320) after pooling\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        # convolutional layer 2 -> input: (16, 180, 320), output: (32, 90, 160) after pooling\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # convolutional layer 3 -> input: (32, 90, 160), output: (64, 45, 80) after pooling\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        # convolutional layer 4 -> input: (64, 45, 80), output: (128, 22, 40) after pooling\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # define dropout layer after convolutional layers\n",
    "        self.dropout_conv = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # define fully connected layers\n",
    "        # fully connected layer 1 -> flattened the input to 512 neurons\n",
    "        self.fc1 = nn.Linear(128 * 22 * 40, 512)\n",
    "        # fully connected layer 2 -> 512 to number of classes \n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        # define dropout layer after fully connected layers\n",
    "        self.dropout_fc = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # apply convolutional layer -> relu -> pooling\n",
    "        X = self.pool(F.relu(self.conv1(X)))    # (3, 360, 640) -> (16, 180, 320)\n",
    "        X = self.pool(F.relu(self.conv2(X)))    # (16, 180, 320) -> (32, 90, 160)\n",
    "        X = self.pool(F.relu(self.conv3(X)))    # (32, 90, 160) -> (64, 45, 80)\n",
    "        X = self.pool(F.relu(self.conv4(X)))    # (64, 45, 80) -> (128, 22, 40)\n",
    "        \n",
    "        # apply dropout layer after convolutional layers\n",
    "        X = self.dropout_conv(X)\n",
    "        \n",
    "        # flatten the output from convolutional layers\n",
    "        X = X.view(-1, 128 * 22 * 40)\n",
    "        \n",
    "        # apply fully connected layers -> relu -> dropout\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.dropout_fc(X)\n",
    "        X = self.fc2(X)\n",
    "        \n",
    "        # return the result\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "model = CNN(num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate gpu if possible, otherwise cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# send the model to the device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batch gradient descent method for training\n",
    "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
    "    # losses will be stored to plot the results\n",
    "    # storage for losses per each epoch\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    \n",
    "    # epoch iteration\n",
    "    for epoch in range(epochs):\n",
    "        ## train mode\n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        \n",
    "        # batch iteration\n",
    "        for inputs, targets in train_loader:\n",
    "            # send data to the device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # zero the parameter gradients to make sure they are zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # save the batch loss\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "        # get train loss per epoch as average loss of all the batches in that epoch\n",
    "        train_loss = np.mean(train_loss)\n",
    "        train_losses[epoch] = train_loss\n",
    "        \n",
    "        ## test mode\n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        \n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        \n",
    "        test_loss = np.mean(test_loss)\n",
    "        test_losses[epoch] = test_loss\n",
    "        \n",
    "        # calculate time spent per epoch\n",
    "        dt = datetime.now() - t0\n",
    "        \n",
    "        # print out the result per epoch\n",
    "        print(f\"Epoch: {epoch+1}/{epochs}, Train loss: {train_loss:.4f}, Test loss: {test_loss:.4f}, Duration: {dt}\")\n",
    "    \n",
    "    # return the results\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the result\n",
    "train_losses, test_losses = batch_gd(\n",
    "    model, criterion, optimizer, train_loader, test_loader, epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the train loss and test loss per epoch\n",
    "plt.plot(train_losses, label=\"Train loss\")\n",
    "plt.plot(test_losses, label=\"Test loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "## train accuracy\n",
    "n_correct = float(0)\n",
    "n_total = float(0)\n",
    "\n",
    "model.eval()\n",
    "for inputs, targets in train_loader:\n",
    "    # send data to the device\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    \n",
    "    # forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # predictions by returning max value label\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    \n",
    "    # update numbers\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "    \n",
    "# calculate train accuracy\n",
    "train_acc = n_correct / n_total\n",
    "print(f\"The number of train images: {n_total}\")\n",
    "\n",
    "## test accuracy\n",
    "n_correct = float(0)\n",
    "n_total = float(0)\n",
    "\n",
    "model.eval()\n",
    "for inputs, targets in test_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "    \n",
    "# calculate train accuracy\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"The number of test images: {n_total}\")\n",
    "\n",
    "# print the result\n",
    "print(f\"Train accuracy: {train_acc:.4f}, Test accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hand_pose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
